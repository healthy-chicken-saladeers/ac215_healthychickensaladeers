{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a5e8ae8",
   "metadata": {},
   "source": [
    "# Querying Stage\n",
    "In this stage, the RAG pipeline extracts the most pertinent context based on a user’s query and forwards it, along with the query, to the LLM to generate a response. This procedure equips the LLM with current knowledge that wasn’t included in its original training data. This also reduces the likelihood of hallucinations, a problem for LLMs when they invent answers for data they were insufficiently trained with. The pivotal challenges in this phase revolve around the retrieval, coordination, and analysis across one or several knowledge bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d19993f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress Pydantic warnings since it's based in llamaindex\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e439d01",
   "metadata": {},
   "source": [
    "## Some hard-coded stuff in this cell\n",
    "* OPEN AI Key\n",
    "* Weaviate IP address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ab6c8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iankelk/anaconda3/lib/python3.11/site-packages/pydantic/_internal/_config.py:267: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.4/migration/\n",
      "  warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Set the OpenAI key and current Weaviate IP to run this notebook\n",
    "OPENAI_KEY = \"sk-KEY\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_KEY\n",
    "\n",
    "WEAVIATE_IP_ADDRESS = \"34.133.13.119\"\n",
    "\n",
    "import weaviate\n",
    "from weaviate import Client\n",
    "from llama_index import VectorStoreIndex\n",
    "from llama_index.storage import StorageContext\n",
    "from llama_index.vector_stores import WeaviateVectorStore\n",
    "from llama_index.vector_stores.types import ExactMatchFilter, MetadataFilters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcd4fc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom prompt to exclude out of context answers\n",
    "from llama_index.prompts import PromptTemplate\n",
    "\n",
    "template = (\"We have provided context information below. If the answer to a query is not contained in this context, \"\n",
    "            \"please only reply that it is not in the context.\"\n",
    "            \"\\n---------------------\\n\"\n",
    "            \"{context_str}\"\n",
    "            \"\\n---------------------\\n\"\n",
    "            \"Given this information, please answer the question: {query_str}\\n\"\n",
    ")\n",
    "qa_template = PromptTemplate(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bebce4",
   "metadata": {},
   "source": [
    "## Some hard-coded stuff in this cell\n",
    "* Weaviate IP address\n",
    "* The websiteAddress obtained from what will probably be a dropdown in the frontend menu\n",
    "* The timestamp obtained from what will probably be a dropdown in the frontend menu\n",
    "* The query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66831c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The information provided does not contain any information about Kim Kardashian.\n"
     ]
    }
   ],
   "source": [
    "# client setup\n",
    "client = weaviate.Client(url=\"http://\" + WEAVIATE_IP_ADDRESS + \":8080\")\n",
    "\n",
    "# construct vector store\n",
    "vector_store = WeaviateVectorStore(weaviate_client=client, index_name=\"Pages\", text_key=\"text\")\n",
    "\n",
    "# setting up the indexing strategy \n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# setup an index for the Vector Store\n",
    "index = VectorStoreIndex.from_vector_store(vector_store, storage_context=storage_context)\n",
    "\n",
    "# Create exact match filters for websiteAddress and timestamp\n",
    "website_address_filter = ExactMatchFilter(key=\"websiteAddress\", value=\"ai21.com\")\n",
    "timestamp_filter = ExactMatchFilter(key=\"timestamp\", value=\"2023-10-06T18-11-24\")\n",
    "\n",
    "# Create a metadata filters instance with the above filters\n",
    "metadata_filters = MetadataFilters(filters=[website_address_filter, timestamp_filter])\n",
    "\n",
    "# Create a query engine with the custom prompt and filters\n",
    "query_engine = index.as_query_engine(text_qa_template=qa_template, filters=metadata_filters)\n",
    "\n",
    "# Execute the query\n",
    "#query_str = \"How was AI21 Studio a game changer?\"\n",
    "query_str = \"Who is Kim Kardashian?\"\n",
    "response = query_engine.query(query_str)\n",
    "\n",
    "# Print the response\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
