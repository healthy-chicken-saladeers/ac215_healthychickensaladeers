{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e20939b",
   "metadata": {},
   "source": [
    "# Indexing Stage\n",
    "In the initial indexing stage, text data must be first collected as documents and metadata. In this implementation, this is performed by the scraping of website. This data must be then split into \"nodes\", which is a represents a \"chunk\" or part of the data containing a certain portion of information. Nodes must are then indexed via an embedding model, where we plan on using OpenAI's Ada v2 embedding model. The embeddings and metadata together create a rich representation to aid in retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a59cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress Pydantic warnings since it's based in llamaindex\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6d6a8a",
   "metadata": {},
   "source": [
    "## Hard-coded stuff in this cell that will be replaced in the cloud function\n",
    "* OPEN AI Key will be an environment variable\n",
    "* Weaviate IP address that we will work on finding programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a80948",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install weaviate-client\n",
    "!pip install openai\n",
    "!pip install llama-index\n",
    "\n",
    "import weaviate\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timezone\n",
    "from llama_index import Document\n",
    "# Suppress Pydantic warnings since it's based in llamaindex\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.vector_stores import WeaviateVectorStore\n",
    "from llama_index import VectorStoreIndex, StorageContext\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.vector_stores.types import ExactMatchFilter, MetadataFilters\n",
    "\n",
    "\n",
    "# Set the OpenAI key and current Weaviate IP to run this notebook\n",
    "OPENAI_KEY = \"OPENAI_KEY\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_KEY\n",
    "\n",
    "WEAVIATE_IP_ADDRESS = \"34.133.13.119\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "934520c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"classes\": [\n",
    "        {\n",
    "            \"class\": \"Document\",\n",
    "            \"description\": \"A full document of text from a scraped webpage with full details.\",\n",
    "            \"invertedIndexConfig\": {\n",
    "                \"indexTimestamps\": True\n",
    "            },\n",
    "            \"vectorizer\": \"text2vec-openai\",\n",
    "            \"moduleConfig\": {\n",
    "                \"generative-openai\": {\n",
    "                    \"model\": \"gpt-3.5-turbo\"\n",
    "                }\n",
    "            },\n",
    "            \"properties\": [\n",
    "                {\n",
    "                    \"name\": \"text\",\n",
    "                    \"dataType\": [\"string\"],\n",
    "                    \"description\": \"The content of the document.\",\n",
    "                    \"indexInverted\": True\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"websiteAddress\",\n",
    "                    \"dataType\": [\"string\"],\n",
    "                    \"description\": \"The address of the website this document comes from.\",\n",
    "                    \"indexInverted\": True\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"timestamp\",\n",
    "                    \"dataType\": [\"date\"],\n",
    "                    \"description\": \"The date and time when the document was scraped.\",\n",
    "                    \"indexInverted\": True\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3098de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date(date_string):\n",
    "    \"\"\"\n",
    "    Convert a date string to RFC 3339 formatted string with timezone.\n",
    "\n",
    "    Parameters:\n",
    "    - date_string (str): Input date string in the format \"%Y-%m-%dT%H-%M-%S\".\n",
    "\n",
    "    Returns:\n",
    "    - str: RFC 3339 formatted date-time string.\n",
    "    \"\"\"\n",
    "    dt_object = datetime.strptime(date_string, \"%Y-%m-%dT%H-%M-%S\")\n",
    "    # convert datetime object to RFC 3339 string (with timezone)\n",
    "    rfc3339_string = dt_object.replace(tzinfo=timezone.utc).isoformat()\n",
    "    return rfc3339_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "391e5e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema was created.\n"
     ]
    }
   ],
   "source": [
    "client = weaviate.Client(url=\"http://\" + WEAVIATE_IP_ADDRESS + \":8080\")\n",
    "\n",
    "# Delete existing schema (caution: this deletes the current structure)\n",
    "client.schema.delete_all()\n",
    "\n",
    "# Here we use the schema created in the previous cell.\n",
    "client.schema.create(schema)\n",
    "print(\"Schema was created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7618991",
   "metadata": {},
   "source": [
    "## Hard-coded stuff in this cell that will be replaced in the cloud function\n",
    "* data_directory will be the bucket\n",
    "* csv_file will be the new file added to the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6967b267",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"./sample_data\"\n",
    "csv_file = 'ai21.com_2023-10-06T18-11-24.csv'\n",
    "# Get the website address and timestamp from the filename\n",
    "websiteAddress, timestamp = csv_file.rsplit('.', 1)[0].split('_')\n",
    "\n",
    "# Read in the CSV\n",
    "df = pd.read_csv(data_directory + \"/\" + csv_file)\n",
    "\n",
    "# Manually assemble the documents\n",
    "documents = []\n",
    "for _, row in df.iterrows():\n",
    "    document = Document(\n",
    "        text=row['text'],\n",
    "        metadata={\n",
    "            'websiteAddress': websiteAddress,\n",
    "            'timestamp': timestamp\n",
    "        }\n",
    "    )\n",
    "    document.doc_id = row['key']\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "439fcff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parser and nodes\n",
    "parser = SimpleNodeParser.from_defaults(chunk_size=1024, chunk_overlap=20)\n",
    "nodes = parser.get_nodes_from_documents(documents)\n",
    "\n",
    "# construct vector store\n",
    "vector_store = WeaviateVectorStore(weaviate_client = client, index_name=\"Pages\", text_key=\"text\")\n",
    "# setting up the storage for the embeddings\n",
    "storage_context = StorageContext.from_defaults(vector_store = vector_store)\n",
    "# set up the index\n",
    "index = VectorStoreIndex(nodes, storage_context=storage_context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
