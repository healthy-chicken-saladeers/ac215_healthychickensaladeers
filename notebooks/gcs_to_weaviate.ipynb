{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Add scraped data from GCS bucket to Weaviate\n",
        "\n",
        "###### Run this notebook to add **new** scarped data for websites in our GCS bucket. Files that already exist in Weaviate will be skipped."
      ],
      "metadata": {
        "id": "V-Pbk2D2a3fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages\n",
        "!pip install weaviate-client\n",
        "!pip install llama-index"
      ],
      "metadata": {
        "id": "tlZq6fQja3pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import json\n",
        "from google.cloud import storage\n",
        "from google.oauth2 import service_account\n",
        "from datetime import datetime, timezone\n",
        "from weaviate import Client\n",
        "import pandas as pd\n",
        "from datetime import datetime, timezone\n",
        "from weaviate import Client\n",
        "from weaviate.exceptions import UnexpectedStatusCodeException\n",
        "from google.cloud import storage\n",
        "\n",
        "# Additional imports for the llama_index module\n",
        "from llama_index import Document\n",
        "from llama_index.node_parser import SimpleNodeParser\n",
        "from llama_index.vector_stores import WeaviateVectorStore\n",
        "from llama_index import VectorStoreIndex, StorageContext\n",
        "from llama_index.storage.storage_context import StorageContext\n",
        "from io import BytesIO\n",
        "from llama_index.vector_stores.types import ExactMatchFilter, MetadataFilters\n",
        "\n",
        "# Define the Weaviate IP address\n",
        "WEAVIATE_IP_ADDRESS = \"34.42.138.162\"\n",
        "\n",
        "# Set OpenAI API key in the environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-OPENAI_API_KEY\""
      ],
      "metadata": {
        "id": "MtaYiYiOa9W-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def authenticate_with_service_account(key_path):\n",
        "    \"\"\"\n",
        "    Authenticate using a service account key.\n",
        "\n",
        "    Parameters:\n",
        "    - key_path (str): Path to the service account key file.\n",
        "\n",
        "    Returns:\n",
        "    - credentials (google.auth.credentials.Credentials): Google Cloud credentials.\n",
        "    \"\"\"\n",
        "    credentials = service_account.Credentials.from_service_account_file(\n",
        "        key_path,\n",
        "        scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
        "    )\n",
        "    return credentials\n",
        "\n",
        "def text_chunk_exists(client, website_address, timestamp):\n",
        "    \"\"\"\n",
        "    Check if a TextChunk with a specific website address and timestamp already exists in Weaviate.\n",
        "\n",
        "    Parameters:\n",
        "    - client (weaviate.Client): The Weaviate client object to interact with the Weaviate instance.\n",
        "    - website_address (str): The website address to check.\n",
        "    - timestamp (str): The timestamp to check in RFC 3339 format.\n",
        "\n",
        "    Returns:\n",
        "    - bool: True if the Pages exists in Weaviate, False otherwise.\n",
        "    \"\"\"\n",
        "\n",
        "    # GraphQL query to retrieve Pages based on website address and timestamp\n",
        "    query = f\"\"\"\n",
        "    {{\n",
        "      Get {{\n",
        "        Pages (where: {{\n",
        "            operator: And\n",
        "            operands: [{{\n",
        "                path: [\"websiteAddress\"],\n",
        "                operator: Equal,\n",
        "                valueString: \"{website_address}\"\n",
        "            }}, {{\n",
        "                path: [\"timestamp\"],\n",
        "                operator: Equal,\n",
        "                valueText: \"{timestamp}\"\n",
        "            }}]\n",
        "        }}) {{\n",
        "          __typename\n",
        "        }}\n",
        "      }}\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    result = client.query.raw(query)\n",
        "    print(result) # Print the result for debugging\n",
        "\n",
        "    # # Check if the Pages exists based on the query results\n",
        "    # return result['data']['Get']['Pages'] is not None\n",
        "\n",
        "    # Check if the Pages exists based on the query results\n",
        "    return len(result['data']['Get']['Pages']) > 0\n",
        "\n",
        "\n",
        "def extract_website_and_timestamp(filename):\n",
        "    \"\"\"\n",
        "    Extract website address and timestamp from a filename.\n",
        "    Split the filename by '_' and check if there are at least two parts\n",
        "\n",
        "    Parameters:\n",
        "    - filename (str): The input filename.\n",
        "\n",
        "    Returns:\n",
        "    - website_address (str): Extracted website address.\n",
        "    - timestamp (str): Extracted timestamp.\n",
        "    \"\"\"\n",
        "    filename_parts = filename.split('_')\n",
        "    if len(filename_parts) >= 2:\n",
        "        website_address, timestamp = filename_parts[0][len(\"data/\"):], filename_parts[1].split('.csv')[0]\n",
        "        return website_address, timestamp\n",
        "    else:\n",
        "        # Handle the case where the filename doesn't match the expected structure\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "Y0zMZWqtio4Q"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Google Cloud Storage client and bucket\n",
        "storage_client = storage.Client(credentials=credentials)\n",
        "bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "# List all files in the bucket\n",
        "files = bucket.list_blobs()\n",
        "\n",
        "# Set up Weaviate client\n",
        "client = Client(url=\"http://\" + WEAVIATE_IP_ADDRESS + \":8080\")\n",
        "\n",
        "# Iterate through each file in the bucket\n",
        "for file in files:\n",
        "    csv_file = os.path.basename(file.name)\n",
        "    print(csv_file)\n",
        "\n",
        "    # Extract website_address and timestamp\n",
        "    website_address, timestamp = extract_website_and_timestamp(file.name)\n",
        "\n",
        "    # Print the extracted values\n",
        "    print(f\"Website Address: {website_address}\")\n",
        "    print(f\"Timestamp: {timestamp}\")\n",
        "\n",
        "    # Now, call the text_chunk_exists function with the extracted values\n",
        "    result = text_chunk_exists(client, website_address, timestamp)\n",
        "    print(result)\n",
        "\n",
        "    # If file is not in Weaviate, add it!\n",
        "    if result == False:\n",
        "      print(f\"Adding {csv_file} to Weaviate!\")\n",
        "\n",
        "      # Get the blob from the bucket\n",
        "      filename = file.name\n",
        "      blob = bucket.blob(filename)\n",
        "\n",
        "      # Download the file contents as bytes\n",
        "      file_contents = blob.download_as_bytes()\n",
        "\n",
        "      # Use BytesIO to convert the bytes content to a file-like object\n",
        "      file_like_object = BytesIO(file_contents)\n",
        "\n",
        "      # Create a Pandas DataFrame from the file-like object\n",
        "      df = pd.read_csv(file_like_object)\n",
        "      print(df.head())\n",
        "\n",
        "      # Manually assemble the documents\n",
        "      documents = []\n",
        "      for _, row in df.iterrows():\n",
        "          document = Document(\n",
        "              text=row['text'],\n",
        "              metadata={\n",
        "                  'websiteAddress': website_address,\n",
        "                  'timestamp': timestamp\n",
        "              }\n",
        "          )\n",
        "          document.doc_id = row['key']\n",
        "          documents.append(document)\n",
        "\n",
        "      # Create the parser and nodes\n",
        "      parser = SimpleNodeParser.from_defaults(chunk_size=1024, chunk_overlap=20)\n",
        "      nodes = parser.get_nodes_from_documents(documents)\n",
        "\n",
        "      # construct vector store\n",
        "      vector_store = WeaviateVectorStore(weaviate_client = client, index_name=\"Pages\", text_key=\"text\")\n",
        "      # setting up the storage for the embeddings\n",
        "      storage_context = StorageContext.from_defaults(vector_store = vector_store)\n",
        "      # set up the index\n",
        "      index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
        "\n",
        "      print(f\"Added {csv_file} to Weaviate!\")"
      ],
      "metadata": {
        "id": "MoajigS5eU1_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}